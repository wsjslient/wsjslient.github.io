<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>My First Blog</title>
    <url>/2021/06/28/first/</url>
    <content><![CDATA[<p><img src="/2021/06/28/first/firstblog.jpg" alt></p>
<div class="note info"><blockquote>
<p>       有一个属于自己的<a href="https://wsjslient.github.io/" target="_blank">空间</a>是一件美好的事情，我会尽我最大的努力来完善这里、充实这里，这是我第一篇的博客。我的博客主要记录学习方面的东西，如果有可能也会记录一些生活的点滴，希望能带给你一些帮助和收获！</p>
</blockquote>
</div>
<span id="more"></span>
<h1>⭐️随便写写</h1>
<blockquote>
<p>       刚毕业那会工作时，还没有写博客记录的习惯。不过在工作中确实有很多知识需要记录，经朋友推荐当时是使用印象笔记来记录知识点。但是慢慢的发现这种方法并不是自己喜欢的，也用不习惯(主要还是自己太蠢了用不好)；后来工作时因为有各种搜索时，又接触到了csdn、github,不过由于自己英文太差，还是csdn用的更多，也开始在csdn上开通了自己的博客【<a href="https://blog.csdn.net/wsjslient/" target="_blank">我的csdn博客</a>】，也慢慢的养成了把自己学习到的知识记录到博客的习惯。渐渐的觉着写博客是一件幸福的事，但是越来越感觉csdn的博客无法满足自己的需求；看到别人的github博客确实很惊艳，首先这个搭建博客的过程确实很不错，而且这个博客你可以根据自己的需要随意变换，还能随意增加很多实用的功能，于是我的博客就开通了，试了很多的主题，还是next最吸引我，next的开发相比其他主题更加的深入，更加的多方面，集成的功能也更多，这也方便了自己的后续开发，希望能让自己的博客越来越好，也希望能认识更多的小伙伴，一起学习，一起进步！</p>
</blockquote>
<h1>⭐️我的工作&amp;兴趣</h1>
<blockquote>
<p>       截止2021年6月，已经入行大数据三年了，主要还是做数据开发方面的工作。对于自己的规划呢，希望能往架构的方向走吧，当然也会有很多基础知识的学习了，所以内容也是集中在这个方面。当然也会有生活向的内容更新，无他只为了记录这美好的生活！</p>
</blockquote>
]]></content>
      <categories>
        <category>daily</category>
      </categories>
      <tags>
        <tag>social</tag>
      </tags>
  </entry>
  <entry>
    <title>Java发送http请求</title>
    <url>/2021/12/14/Java%E5%8F%91%E9%80%81http%E8%AF%B7%E6%B1%82/</url>
    <content><![CDATA[<h1>前言</h1>
<blockquote>
<p>项目上有时候需要发送http请求并获取返回的Json结果，这里记录下请求和接受返回的方法。</p>
</blockquote>
<span id="more"></span>
<h1>使用Java自带方法发送http请求</h1>
<ul>
<li>参数：
<ul>
<li>请求地址：url  <code>e.g. http://192.168.1.107:7777/api/test</code>;</li>
<li>参数：bodys  <code>键值对Map对象</code>;</li>
<li>请求头：headers <code>键值对Map对象</code>;</li>
<li>方法名：method <code>e.g. POST/PUT</code>;</li>
</ul>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> url</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> bodys</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> headers</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> method</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">sendPostRequest</span><span class="params">(String url, Map&lt;String,String&gt; bodys,Map&lt;String,String&gt; headers,String method)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    Set&lt;Map.Entry&lt;String,String&gt;&gt; entrys = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span>(bodys!=<span class="keyword">null</span> &amp;&amp; !bodys.isEmpty())&#123;</span><br><span class="line">        entrys = bodys.entrySet();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : entrys) &#123;</span><br><span class="line">            builder.append(entry.getKey()).append(<span class="string">&quot;=&quot;</span>).append(URLEncoder.encode(entry.getValue()==<span class="keyword">null</span>?<span class="string">&quot;&quot;</span>:entry.getValue(),<span class="string">&quot;UTF-8&quot;</span>)).append(<span class="string">&quot;&amp;&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        builder.deleteCharAt(builder.length() - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    URL _url = <span class="keyword">new</span> URL(url);</span><br><span class="line">    HttpURLConnection con = (HttpURLConnection)_url.openConnection();</span><br><span class="line">    <span class="keyword">if</span>(headers!=<span class="keyword">null</span> &amp;&amp; !headers.isEmpty())&#123;</span><br><span class="line">        entrys = headers.entrySet();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : entrys) &#123;</span><br><span class="line">            con.setRequestProperty(entry.getKey(),entry.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    con.setRequestMethod(method);</span><br><span class="line">    con.setDoOutput(<span class="keyword">true</span>);</span><br><span class="line">    con.setDoInput(<span class="keyword">true</span>);</span><br><span class="line">    OutputStream os = con.getOutputStream();</span><br><span class="line">    os.write(builder.toString().getBytes(<span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">    os.flush();</span><br><span class="line">    os.close();</span><br><span class="line"></span><br><span class="line">    String str = <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span>(con.getResponseCode() == <span class="number">200</span>)&#123;</span><br><span class="line">        BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(con.getInputStream()));</span><br><span class="line">        str = reader.readLine();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> str;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH集群外配置非Kerberos环境的Gateway节点</title>
    <url>/2021/10/19/CDH%E9%9B%86%E7%BE%A4%E5%A4%96%E9%85%8D%E7%BD%AE%E9%9D%9EKerberos%E7%8E%AF%E5%A2%83%E7%9A%84Gateway%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<h1>前言</h1>
<blockquote>
<p>在使用CDH集群时，总会遇到在集群外的服务器想访问大数据集群的服务的情况（例如第三方服务的服务器），这时候又不想添加到CDH集群中管理，这时可以在集群外不通过CM部署一个新的Gateway节点。</p>
</blockquote>
<span id="more"></span>
<ul>
<li>测试环境
<ul>
<li>CDH:5.16.1-1.cdh5.16.1.p0.3</li>
<li>操作系统：RedHat6.7</li>
</ul>
</li>
</ul>
<h1>一、部署Gateway节点</h1>
<blockquote>
<p>在非CDH的服务器上部署Gateway节点</p>
</blockquote>
<h2 id="1-1-将集群的hosts文件同步至新Gateway节点">1.1 将集群的hosts文件同步至新Gateway节点</h2>
<blockquote>
<p>将CM界面所有的Gateway节点的IP地址映射加入到新Gateway节点的hosts文件中</p>
</blockquote>
<h2 id="1-2-安装Java环境">1.2 安装Java环境</h2>
<blockquote>
<p>如果本机有java环境的话，则无需操作此步骤；若本机无Java环境，则可将集群的Java目录整体拷贝至该节点下</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">登录集群任意节点，将Java目录拷贝至新Gateway节点</span></span><br><span class="line">[root@cdh01 ~]$ scp -r /usr/java/jdk1.8.0_141/ single:/usr/java/</span><br></pre></td></tr></table></figure>
<h2 id="1-3-压缩-opt-cloudera-parcels目录拷贝至新Gateway节点">1.3 压缩/opt/cloudera/parcels目录拷贝至新Gateway节点</h2>
<ul>
<li>先在集群的任意一台节点上压缩并复制至新节点</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">这里压缩了两个目录到安装包里，CDH那个为软链，也可以只压缩实际目录</span></span><br><span class="line">[root@cdh01 parcels]$ tar -zcvf cdh.tar.gz CDH-5.14.2-1.cdh5.14.2.p0.3/ CDH/</span><br><span class="line">[root@cdh01 ~]$ scp -r /opt/cloudera/parcels/cdh.tar.gz single:/opt</span><br></pre></td></tr></table></figure>
<ul>
<li>新Gateway节点创建文件夹并解压</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@single ~]$ mkdir -p /opt/cloudera/parcels</span><br><span class="line">[root@single ~]$ tar -zxvf /opt/cdh.tar.gz -C /opt/cloudear/parcels/</span><br></pre></td></tr></table></figure>
<h2 id="1-4-在新Gateway节点创建配置文件存放目录">1.4 在新Gateway节点创建配置文件存放目录</h2>
<ul>
<li>新Gateway节点创建目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据需要创建相应配置文件存放目录</span></span><br><span class="line">[root@single ~]$ mkdir -p /etc/hadoop/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/hbase/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/hive/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/spark/conf</span><br></pre></td></tr></table></figure>
<ul>
<li>登录拥有对应服务的Gateway节点将/etc/*/conf目录下的配置拷贝至新Gateway节点下</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /etc/hadoop/conf/* single:/etc/hadoop/conf/</span><br><span class="line">scp -r /etc/hbase/conf/* single:/etc/hbase/conf/</span><br><span class="line">scp -r /etc/hive/conf/* single:/etc/hive/conf/</span><br><span class="line">scp -r /etc/spark/conf/* single:/etc/spark/conf/</span><br></pre></td></tr></table></figure>
<h2 id="1-5-配置新Gateway节点环境变量">1.5 配置新Gateway节点环境变量</h2>
<ul>
<li>修改/etc/profile，增加如下配置</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 这里注意和实际情况保持一致</span></span><br><span class="line">export  JAVA_HOME=/usr/java/jdk1.8.0_141</span><br><span class="line">export CDH_HOME=/opt/cloudera/parcels/CDH</span><br><span class="line">export PATH=$CDH_HOME/bin:$PATH</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启环境变量</span></span><br><span class="line">[root@single ~]$ source /etc/profile</span><br></pre></td></tr></table></figure>
<h2 id="二、新Gateway服务测试">二、新Gateway服务测试</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop测试</span></span><br><span class="line">[root@single ~]$ hadoop fs -ls /</span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn测试</span></span><br><span class="line">[root@single ~]$ yarn application --list</span><br><span class="line"><span class="meta">#</span><span class="bash"> hive测试</span></span><br><span class="line">[root@single ~]$ beeline -u jdbd:hive2//cdh01:10000/ods  -n test -p test123</span><br><span class="line"><span class="meta">#</span><span class="bash"> hbase测试</span></span><br><span class="line">[root@single ~]$ hbase shell</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>CDH</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark Operator</title>
    <url>/2021/09/29/spark-operator/</url>
    <content><![CDATA[<h1>🌈RDD算子</h1>
<p><code>Spark RDD算子一览：</code></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">++                    first                    max                  take</span><br><span class="line">aggregate             flatMap                  min                  takeAsync</span><br><span class="line">barrier               fold                     name                 takeOrdered</span><br><span class="line">cache                 foreach                  partitioner          takeSample</span><br><span class="line">canEqual              foreachAsync             partitions           toDF</span><br><span class="line">cartesian             foreachPartition         persist              toDS</span><br><span class="line">checkpoint            foreachPartitionAsync    pipe                 toDebugString</span><br><span class="line">coalesce              getCheckpointFile        preferredLocations   toJavaRDD</span><br><span class="line">collect               getNumPartitions         productArity         toLocalIterator</span><br><span class="line">collectAsync          getStorageLevel          productElement       toString</span><br><span class="line">compute               glom                     productIterator      top</span><br><span class="line">context               groupBy                  productPrefix        treeAggregate</span><br><span class="line">copy                  id                       randomSplit          treeReduce</span><br><span class="line">count                 intersection             reduce               union</span><br><span class="line">countApprox           isCheckpointed           repartition          unpersist</span><br><span class="line">countApproxDistinct   isEmpty                  sample               zip</span><br><span class="line">countAsync            iterator                 saveAsObjectFile     zipPartitions</span><br><span class="line">countByValue          keyBy                    saveAsTextFile       zipWithIndex</span><br><span class="line">countByValueApprox    localCheckpoint          setName              zipWithUniqueId</span><br><span class="line">dependencies          map                      sortBy</span><br><span class="line">distinct              mapPartitions            sparkContext</span><br><span class="line">filter                mapPartitionsWithIndex   subtract</span><br></pre></td></tr></table></figure>
<hr>
]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
