<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>My First Blog</title>
    <url>/2021/06/28/first/</url>
    <content><![CDATA[<p><img src="/2021/06/28/first/firstblog.jpg" alt></p>
<div class="note info"><blockquote>
<p>       有一个属于自己的<a href="https://wsjslient.github.io/" target="_blank">空间</a>是一件美好的事情，我会尽我最大的努力来完善这里、充实这里，这是我第一篇的博客。我的博客主要记录学习方面的东西，如果有可能也会记录一些生活的点滴，希望能带给你一些帮助和收获！</p>
</blockquote>
</div>
<span id="more"></span>
<h1>⭐️随便写写</h1>
<blockquote>
<p>       刚毕业那会工作时，还没有写博客记录的习惯。不过在工作中确实有很多知识需要记录，经朋友推荐当时是使用印象笔记来记录知识点。但是慢慢的发现这种方法并不是自己喜欢的，也用不习惯(主要还是自己太蠢了用不好)；后来工作时因为有各种搜索时，又接触到了csdn、github,不过由于自己英文太差，还是csdn用的更多，也开始在csdn上开通了自己的博客【<a href="https://blog.csdn.net/wsjslient/" target="_blank">我的csdn博客</a>】，也慢慢的养成了把自己学习到的知识记录到博客的习惯。渐渐的觉着写博客是一件幸福的事，但是越来越感觉csdn的博客无法满足自己的需求；看到别人的github博客确实很惊艳，首先这个搭建博客的过程确实很不错，而且这个博客你可以根据自己的需要随意变换，还能随意增加很多实用的功能，于是我的博客就开通了，试了很多的主题，还是next最吸引我，next的开发相比其他主题更加的深入，更加的多方面，集成的功能也更多，这也方便了自己的后续开发，希望能让自己的博客越来越好，也希望能认识更多的小伙伴，一起学习，一起进步！</p>
</blockquote>
<h1>⭐️我的工作&amp;兴趣</h1>
<blockquote>
<p>       截止2021年6月，已经入行大数据三年了，主要还是做数据开发方面的工作。对于自己的规划呢，希望能往架构的方向走吧，当然也会有很多基础知识的学习了，所以内容也是集中在这个方面。当然也会有生活向的内容更新，无他只为了记录这美好的生活！</p>
</blockquote>
]]></content>
      <categories>
        <category>daily</category>
      </categories>
      <tags>
        <tag>social</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH集群外配置非Kerberos环境的Gateway节点</title>
    <url>/2021/10/19/CDH%E9%9B%86%E7%BE%A4%E5%A4%96%E9%85%8D%E7%BD%AE%E9%9D%9EKerberos%E7%8E%AF%E5%A2%83%E7%9A%84Gateway%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<h1>前言</h1>
<blockquote>
<p>在使用CDH集群时，总会遇到在集群外的服务器想访问大数据集群的服务的情况（例如第三方服务的服务器），这时候又不想添加到CDH集群中管理，这时可以在集群外不通过CM部署一个新的Gateway节点。</p>
</blockquote>
<span id="more"></span>
<ul>
<li>测试环境
<ul>
<li>CDH:5.16.1-1.cdh5.16.1.p0.3</li>
<li>操作系统：RedHat6.7</li>
</ul>
</li>
</ul>
<h1>一、部署Gateway节点</h1>
<blockquote>
<p>在非CDH的服务器上部署Gateway节点</p>
</blockquote>
<h2 id="1-1-将集群的hosts文件同步至新Gateway节点">1.1 将集群的hosts文件同步至新Gateway节点</h2>
<blockquote>
<p>将CM界面所有的Gateway节点的IP地址映射加入到新Gateway节点的hosts文件中</p>
</blockquote>
<h2 id="1-2-安装Java环境">1.2 安装Java环境</h2>
<blockquote>
<p>如果本机有java环境的话，则无需操作此步骤；若本机无Java环境，则可将集群的Java目录整体拷贝至该节点下</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">登录集群任意节点，将Java目录拷贝至新Gateway节点</span></span><br><span class="line">[root@cdh01 ~]$ scp -r /usr/java/jdk1.8.0_141/ single:/usr/java/</span><br></pre></td></tr></table></figure>
<h2 id="1-3-压缩-opt-cloudera-parcels目录拷贝至新Gateway节点">1.3 压缩/opt/cloudera/parcels目录拷贝至新Gateway节点</h2>
<ul>
<li>先在集群的任意一台节点上压缩并复制至新节点</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">这里压缩了两个目录到安装包里，CDH那个为软链，也可以只压缩实际目录</span></span><br><span class="line">[root@cdh01 parcels]$ tar -zcvf cdh.tar.gz CDH-5.14.2-1.cdh5.14.2.p0.3/ CDH/</span><br><span class="line">[root@cdh01 ~]$ scp -r /opt/cloudera/parcels/cdh.tar.gz single:/opt</span><br></pre></td></tr></table></figure>
<ul>
<li>新Gateway节点创建文件夹并解压</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@single ~]$ mkdir -p /opt/cloudera/parcels</span><br><span class="line">[root@single ~]$ tar -zxvf /opt/cdh.tar.gz -C /opt/cloudear/parcels/</span><br></pre></td></tr></table></figure>
<h2 id="1-4-在新Gateway节点创建配置文件存放目录">1.4 在新Gateway节点创建配置文件存放目录\</h2>
<ul>
<li>新Gateway节点创建目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据需要创建相应配置文件存放目录</span></span><br><span class="line">[root@single ~]$ mkdir -p /etc/hadoop/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/hbase/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/hive/conf</span><br><span class="line">[root@single ~]$ mkdir -p /etc/spark/conf</span><br></pre></td></tr></table></figure>
<ul>
<li>登录拥有对应服务的Gateway节点将/etc/*/conf目录下的配置拷贝至新Gateway节点下</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /etc/hadoop/conf/* single:/etc/hadoop/conf/</span><br><span class="line">scp -r /etc/hbase/conf/* single:/etc/hbase/conf/</span><br><span class="line">scp -r /etc/hive/conf/* single:/etc/hive/conf/</span><br><span class="line">scp -r /etc/spark/conf/* single:/etc/spark/conf/</span><br></pre></td></tr></table></figure>
<h2 id="1-5-配置新Gateway节点环境变量">1.5 配置新Gateway节点环境变量</h2>
<ul>
<li>修改/etc/profile，增加如下配置</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 这里注意和实际情况保持一致</span></span><br><span class="line">export  JAVA_HOME=/usr/java/jdk1.8.0_141</span><br><span class="line">export CDH_HOME=/opt/cloudera/parcels/CDH</span><br><span class="line">export PATH=$CDH_HOME/bin:$PATH</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启环境变量</span></span><br><span class="line">[root@single ~]$ source /etc/profile</span><br></pre></td></tr></table></figure>
<h2 id="二、新Gateway服务测试">二、新Gateway服务测试</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop测试</span></span><br><span class="line">[root@single ~]$ hadoop fs -ls /</span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn测试</span></span><br><span class="line">[root@single ~]$ yarn application --list</span><br><span class="line"><span class="meta">#</span><span class="bash"> hive测试</span></span><br><span class="line">[root@single ~]$ beeline -u jdbd:hive2//cdh01:10000/ods  -n test -p test123</span><br><span class="line"><span class="meta">#</span><span class="bash"> hbase测试</span></span><br><span class="line">[root@single ~]$ hbase shell</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>CDH</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark Operator</title>
    <url>/2021/09/29/spark-operator/</url>
    <content><![CDATA[<h1>🌈RDD算子</h1>
<p><code>Spark RDD算子一览：</code></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">++                    first                    max                  take</span><br><span class="line">aggregate             flatMap                  min                  takeAsync</span><br><span class="line">barrier               fold                     name                 takeOrdered</span><br><span class="line">cache                 foreach                  partitioner          takeSample</span><br><span class="line">canEqual              foreachAsync             partitions           toDF</span><br><span class="line">cartesian             foreachPartition         persist              toDS</span><br><span class="line">checkpoint            foreachPartitionAsync    pipe                 toDebugString</span><br><span class="line">coalesce              getCheckpointFile        preferredLocations   toJavaRDD</span><br><span class="line">collect               getNumPartitions         productArity         toLocalIterator</span><br><span class="line">collectAsync          getStorageLevel          productElement       toString</span><br><span class="line">compute               glom                     productIterator      top</span><br><span class="line">context               groupBy                  productPrefix        treeAggregate</span><br><span class="line">copy                  id                       randomSplit          treeReduce</span><br><span class="line">count                 intersection             reduce               union</span><br><span class="line">countApprox           isCheckpointed           repartition          unpersist</span><br><span class="line">countApproxDistinct   isEmpty                  sample               zip</span><br><span class="line">countAsync            iterator                 saveAsObjectFile     zipPartitions</span><br><span class="line">countByValue          keyBy                    saveAsTextFile       zipWithIndex</span><br><span class="line">countByValueApprox    localCheckpoint          setName              zipWithUniqueId</span><br><span class="line">dependencies          map                      sortBy</span><br><span class="line">distinct              mapPartitions            sparkContext</span><br><span class="line">filter                mapPartitionsWithIndex   subtract</span><br></pre></td></tr></table></figure>
<hr>
]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
